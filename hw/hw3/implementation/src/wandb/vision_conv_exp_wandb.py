# -*- coding: utf-8 -*-
"""vision_conv_exp_wandb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v4sq-KmvDG0n2Ou0luG-ytX0r1H9-9zo
"""

from google.colab import drive
import re
drive.mount('/content/drive')

# !tar -xzvf "/content/drive/MyDrive/CENG_483/HW_3/the3_data.tar.gz" -C "/content/drive/MyDrive/CENG_483/HW_3/"

# !tar -xzvf "/content/drive/MyDrive/CENG_483/HW_3/src.tar.gz" -C .

# --- imports ---
from ast import With
import torch
import os
import matplotlib.pyplot as plt
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms as transforms
import hw3utils
torch.multiprocessing.set_start_method('spawn', force=True)

# Feel free to change / extend / adapt this source code as needed to complete the homework, based on its requirements.
# This code is given as a starting point.
#
# REFEFERENCES
# The code is partly adapted from pytorch tutorials, including https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html

# ---- hyper-parameters ----
# You should tune these hyper-parameters using:
# (i) your reasoning and observations, 
# (ii) by tuning it on the validation set, using the techniques discussed in class.
# You definitely can add more hyper-parameters here.
batch_size = 16
max_num_epoch = 100
hps = {'lr':0.001}

# ---- options ----
DEVICE_ID = 'cuda:0' # set to 'cpu' for cpu, 'cuda' / 'cuda:0' or similar for gpu.
# device = torch.device(DEVICE_ID)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print('device: ' + str(device))

LOG_DIR = 'checkpoints_tmp'

VISUALIZE = False # set True to visualize input, prediction and the output from the last batch
LOAD_CHKPT = False

# Ensure deterministic behavior
import random
from tqdm.notebook import tqdm
torch.backends.cudnn.deterministic = True
random.seed(hash("setting random seeds") % 2**32 - 1)
np.random.seed(hash("improves reproducibility") % 2**32 - 1)
torch.manual_seed(hash("by removing stochasticity") % 2**32 - 1)
torch.cuda.manual_seed_all(hash("so runs are repeatable") % 2**32 - 1)

# !pip install wandb --upgrade

import wandb

wandb.login()

config = dict(
    epochs=max_num_epoch,
    batch_size=batch_size,
    learning_rate=hps['lr'],
    architecture="CNN")

def model_pipeline(hyperparameters):

      # tell wandb to get started
      wandb.init(project="vision", entity="alpayozkan", config=hyperparameters)
      # access all HPs through wandb.config, so logging matches execution!
      config = wandb.config

      # make the model, data, and optimization problem
      model, train_loader, valid_loader, test_loader, criterion, optimizer = make(config)
      # print(len(train_loader))
      print(model)

      # premature test for getting the random value
      # test_no_log(model, test_loader)
      
      # and use them to train the model
      train(model, train_loader, valid_loader, criterion, optimizer, config)

      # and test its final performance
      # test(model, test_loader)

      return model

def make(config):
    # ---- training code -----
    
    
    # Make the model
    model = Net().to(device=device)
    criterion = nn.MSELoss()
    optimizer = optim.SGD(model.parameters(), lr=config.learning_rate)
    
    # Make the data
    train_loader, valid_loader, test_loader = get_loaders(config.batch_size, device)

    return model, train_loader, valid_loader, test_loader, criterion, optimizer

# ---- utility functions -----
def get_loaders(batch_size,device):
    data_root = '/content/drive/MyDrive/CENG_483/HW_3/ceng483-s19-hw3-dataset' # modified this otherwise received error
    
    train_set = hw3utils.HW3ImageFolder(root=os.path.join(data_root,'train'),device=device)
    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)
    
    valid_set = hw3utils.HW3ImageFolder(root=os.path.join(data_root,'val'),device=device)
    valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=0)
    
    test_loader = None
    # Note: you may later add test_loader to here.

    # ama ayri test data si yok o zaman valid i parcalicam ?!
    # test directory sindekiler renkli degil
    return train_loader, valid_loader, test_loader

# ---- ConvNet -----
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # burda en fazla 4 conv ?
        # fcc ?
        # network 3-4 conv la bu task i cozebilecek mi, baktigim paperdaki network cok daha complex idi
        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)
        self.conv2 = nn.Conv2d(8, 8, 3, padding=1)
        self.conv3 = nn.Conv2d(8, 3, 3, padding=1)
        self.relu = nn.ReLU()

    def forward(self, grayscale_image):
        # apply your network's layers in the following lines:      
        x = self.relu(self.conv1(grayscale_image))
        x = self.relu(self.conv2(x))
        x = self.conv3(x)
        return x

def train(model, train_loader, valid_loader, criterion, optimizer, config):
    # Tell wandb to watch what the model gets up to: gradients, weights, and more!
    wandb.watch(model, criterion, log="all", log_freq=10)

    # Run training and track with wandb
    total_batches = len(train_loader) * config.epochs
    
    print('training begins')
    for epoch in tqdm(range(config.epochs)):
        loss_valid_c = 0
        loss_train_c = 0

        example_ct_train = 0  # number of examples seen Train
        example_ct_valid = 0  # number of examples seen Valid
        batch_ct_train = 0
        batch_ct_valid = 0

        model.train()
        for _, (images, labels) in enumerate(train_loader):

            loss_train = train_batch(images, labels, model, optimizer, criterion)
            loss_train_c += loss_train.item() 
            example_ct_train +=  len(images)
            batch_ct_train += 1

            #  if ((batch_ct + 1) % 25) == 0:
            #     train_log(train_loss, example_ct, epoch)
        
        model.eval()
        with torch.no_grad():
          for _, (images, labels) in enumerate(valid_loader):
            example_ct_valid +=  len(images)
            batch_ct_valid += 1

            loss_valid = valid_batch(images, labels, model, criterion)
            loss_valid_c += loss_valid.item()
            
        loss_train = loss_train_c / example_ct_train
        loss_valid = loss_valid_c / example_ct_valid
        
        loss_log(loss_train, loss_valid, epoch)


        print('Saving the model, end of epoch %d' % (epoch+1))
        if not os.path.exists(LOG_DIR):
            os.makedirs(LOG_DIR)
        torch.save(net.state_dict(), os.path.join(LOG_DIR,'checkpoint.pt'))
        hw3utils.visualize_batch(inputs,preds,targets,os.path.join(LOG_DIR,'example' + str(epoch+1) + '.png'))
    print('Finished Training')

def train_batch(images, labels, model, optimizer, criterion):
    images, labels = images.to(device), labels.to(device)
    
    outputs = model(images)
    
    loss = criterion(outputs, labels)
    
    optimizer.zero_grad()
    loss.backward()

    optimizer.step()

    return loss


def valid_batch(images, labels, model, criterion):
    images, labels = images.to(device), labels.to(device)
    predicted = model(images)
    loss = criterion(predicted, labels)
    return loss

def loss_log(loss_train, loss_valid, epoch):
    # Where the magic happens
    wandb.log({"epoch": epoch+1, "train_loss": loss_train, "valid_loss": loss_valid})
    print(f"Epochs " + epoch+1 + f" Train loss: {loss_train:.3f}" + f" Valid loss: {loss_valid:.3f}")

def test(model, test_loader):
    model.eval()
    # ERROR: TEST i update l, su andaki hatali gibi
    # https://colab.research.google.com/drive/1vraYK2z8CJsqv5Mxe6h3VODQe_TvBmO9#scrollTo=sq4iJCnqohnf
    # check_accuracy  
    
    # Run the model on some test examples
    with torch.no_grad():
        loss, total = 0, 0
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss += F.mse_loss(outputs, labels)
            total += labels.size(0)
            
            

        print(f"Loss of the model on the {total} " +
              f"test images: {loss / total}")
        
        wandb.log({"test images (mse)": loss / total})

    # Save the model in the exchangeable ONNX format
    torch.onnx.export(model, images, "model.onnx")
    wandb.save("model.onnx")

def test_no_log(model, test_loader):
    model.eval()

    # Run the model on some test examples
    with torch.no_grad():
        loss, total = 0, 0
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss += F.mse_loss(outputs, labels)
            total += labels.size(0)
        print(f"Loss of the model on the {total} " + f"test images: {loss / total}")

model = model_pipeline(config)

print('training begins')
for epoch in range(max_num_epoch):  
    
    running_loss = 0.0 # training loss of the network
    net.train()
    for iteri, data in enumerate(train_loader, 0):
        inputs, targets = data # inputs: low-resolution images, targets: high-resolution images.

        optimizer.zero_grad() # zero the parameter gradients

        # do forward, backward, SGD step
        preds = net(inputs)
        loss = criterion(preds, targets)
        loss.backward()
        optimizer.step()

        # print loss
        running_loss += loss.item()
        print_n = 100 # feel free to change this constant
        if iteri % print_n == (print_n-1):    # print every print_n mini-batches
            print('[%d, %5d] train-loss: %.3f' %
                  (epoch + 1, iteri + 1, running_loss / print_n))
            running_loss = 0.0
            # note: you most probably want to track the progress on the validation set as well (needs to be implemented)

        if (iteri==0) and VISUALIZE: 
            hw3utils.visualize_batch(inputs,preds,targets)


    running_loss_valid = 0.0 # validation loss
    net.eval()
    with torch.no_grad():
        for iteri, data in enumerate(valid_loader, 0):
            inputs, targets = data # inputs: low-resolution images, targets: high-resolution images.
            preds = net(inputs)
            loss = criterion(preds, targets)
            running_loss_valid += loss.item()
            print_n = 100 # feel free to change this constant
            if iteri % print_n == (print_n-1):    # print every print_n mini-batches
                print('[%d, %5d] valid-loss: %.3f' %
                    (epoch + 1, iteri + 1, running_loss_valid / print_n))
                running_loss_valid = 0.0

    print('Saving the model, end of epoch %d' % (epoch+1))
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)
    torch.save(net.state_dict(), os.path.join(LOG_DIR,'checkpoint.pt'))
    hw3utils.visualize_batch(inputs,preds,targets,os.path.join(LOG_DIR,'example.png'))

print('Finished Training')